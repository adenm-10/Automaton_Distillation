entered training run...


============================================
Discrete Steps until Terminal State: 1000
Continuous Steps until Terminal State: 1000
3.7.2 | packaged by conda-forge | (default, Mar 20 2019, 01:46:52) 
[GCC 7.3.0]
/lustre/fs1/home/amckinney/Local_Neuro_Symbolic
Bounding Persist: <class 'bool'>, True
Bounding Distance: <class 'int'>, 6
Terminal Reward: <class 'int'>, 35
Sequence Level: <class 'int'>, 2
Dungeon Quest LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


imported all dependencies, checking for cuda

==============
Cuda detected!
==============

[<discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x2b47e40f16d8>, <discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x2b47e40f1710>, <discrete.lib.automaton.mine_aps.MineInfoAutAP object at 0x2b47e40f1748>]


============================================
Training Teacher / Independent DDPG Agent
Max Training Steps: 1000000
LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


Starting training at: 2024-07-24 02:58:04
Env Config: EnvConfig(env_name='MineWorldEnv-v1', kwargs={'config': <discrete.lib.env.mineworldenv.MineWorldConfig object at 0x2b47e40f15f8>}, wrapper_cls=<class 'discrete.lib.env.rew_every_step.RewEveryStep'>, wrapper_kwargs={'rew_per_step': -0.1})

Env Name: MineWorldEnv-v1
Observation Space: Box(13,)
Automaton Num States: 5
Action Space: Box(1,)
input shape: (13,)
Agent Name: DDPG Agent
Loading from checkpoint
input shape: (13,)
input shape: (13,)
Actor Learning Rate: 0.0001
Critic Learning Rate: 0.001
