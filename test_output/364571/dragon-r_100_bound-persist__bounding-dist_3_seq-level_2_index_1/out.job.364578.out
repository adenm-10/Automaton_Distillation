entered training run...


============================================
Discrete Steps until Terminal State: 1000
Continuous Steps until Terminal State: 1000
3.7.2 | packaged by conda-forge | (default, Mar 20 2019, 01:46:52) 
[GCC 7.3.0]
/lustre/fs1/home/amckinney/Local_Neuro_Symbolic
Bounding Persist: <class 'bool'>, False
Bounding Distance: <class 'int'>, 2
Terminal Reward: <class 'int'>, 10
Sequence Level: <class 'int'>, 2
Dungeon Quest LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


imported all dependencies, checking for cuda

==============
Cuda detected!
==============

[<discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x14b737dd1198>, <discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x14b737dd11d0>, <discrete.lib.automaton.mine_aps.MineInfoAutAP object at 0x14b737dd1208>]


============================================
Training Teacher / Independent DDPG Agent
Max Training Steps: 1000000
LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


Starting training at: 2024-08-26 18:04:19
Env Config: EnvConfig(env_name='MineWorldEnv-v1', kwargs={'config': <discrete.lib.env.mineworldenv.MineWorldConfig object at 0x14b737dd10b8>}, wrapper_cls=<class 'discrete.lib.env.rew_every_step.RewEveryStep'>, wrapper_kwargs={'rew_per_step': -0.1})

Env Name: MineWorldEnv-v1
Observation Space: Box(16,)
Automaton Num States: 5
Action Space: Box(1,)
Agent Name: TD3 Agent
Loading from checkpoint
Actor Learning Rate: 0.0003
Critic Learning Rate: 0.0003
