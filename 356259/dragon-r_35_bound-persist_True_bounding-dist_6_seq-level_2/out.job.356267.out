entered training run...


============================================
Discrete Steps until Terminal State: 1000
Continuous Steps until Terminal State: 1000
3.7.2 | packaged by conda-forge | (default, Mar 20 2019, 01:46:52) 
[GCC 7.3.0]
/lustre/fs1/home/amckinney/Local_Neuro_Symbolic
Bounding Persist: <class 'bool'>, True
Bounding Distance: <class 'int'>, 6
Terminal Reward: <class 'int'>, 35
Sequence Level: <class 'int'>, 2
Dungeon Quest LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


imported all dependencies, checking for cuda

==============
Cuda detected!
==============

[<discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x2b938e5a4080>, <discrete.lib.automaton.mine_aps.MineInventoryAP object at 0x2b938e5a40b8>, <discrete.lib.automaton.mine_aps.MineInfoAutAP object at 0x2b938e5a40f0>]


============================================
Training Teacher / Independent DDPG Agent
Max Training Steps: 1000000
LTLF: F(dragon) & (!sword U key) & (!dragon U sword)
============================================


Starting training at: 2024-07-21 13:00:23
Env Config: EnvConfig(env_name='MineWorldEnv-v1', kwargs={'config': <discrete.lib.env.mineworldenv.MineWorldConfig object at 0x2b938e59af60>}, wrapper_cls=<class 'discrete.lib.env.rew_every_step.RewEveryStep'>, wrapper_kwargs={'rew_per_step': -0.1})

Env Name: MineWorldEnv-v1
Observation Space: Box(8, 2)
Automaton Num States: 5
Action Space: Box(1,)
input shape: (8, 2)
Agent Name: DDPG Agent
NOT Loading from checkpoint
input shape: (8, 2)
input shape: (8, 2)
Actor Learning Rate: 0.0001
Critic Learning Rate: 0.001
